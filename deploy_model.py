#!/usr/bin/env python3
"""
Model Deployment Script for AutoTune Integration
Created by Sergie Code

This script demonstrates how to train and deploy a model from the ML trainer
to the real-time C++ engine.
"""
import os
import torch
import numpy as np
import json
import shutil
from pathlib import Path
import sys

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

def train_and_deploy_model():
    """Train a simple model and deploy it to the C++ engine"""
    print("üöÄ AutoTune Model Training and Deployment")
    print("=" * 50)
    
    try:
        from src.models.pitch_correction_net import PitchCorrectionNet
        from src.data.audio_preprocessor import AudioPreprocessor
        
        # Step 1: Create and train model (simplified for demo)
        print("\nüìö Step 1: Creating model...")
        model = PitchCorrectionNet(
            input_size=512,
            hidden_size=128,
            num_layers=2,
            dropout=0.0  # No dropout for inference
        )
        model.eval()
        print(f"‚úÖ Model created with {sum(p.numel() for p in model.parameters()):,} parameters")
        
        # Step 2: Quick training simulation (normally you'd train on real data)
        print("\nüèãÔ∏è Step 2: Training simulation...")
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = torch.nn.MSELoss()
        
        # Simulate training on synthetic data
        for epoch in range(5):
            # Generate synthetic training data
            audio_buffer = torch.randn(4, 512)
            target_pitch = torch.randint(200, 800, (4, 1)).float()
            correction_strength = torch.rand(4, 1)
            
            # Synthetic target (in practice, this would be clean/corrected audio)
            target_audio = audio_buffer + 0.1 * torch.randn_like(audio_buffer)
            
            # Forward pass
            output = model(audio_buffer, target_pitch, correction_strength)
            loss = criterion(output[0], target_audio)
            
            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            if epoch % 2 == 0:
                print(f"  Epoch {epoch+1}/5: Loss = {loss.item():.4f}")
        
        print("‚úÖ Training simulation completed")
        
        # Step 3: Export to ONNX
        print("\nüì¶ Step 3: Exporting to ONNX...")
        
        # Create export directory
        export_dir = Path("models/exported")
        export_dir.mkdir(parents=True, exist_ok=True)
        
        # Prepare for export
        model.eval()
        audio_buffer = torch.randn(1, 512)
        target_pitch = torch.tensor([[440.0]])
        correction_strength = torch.tensor([[0.5]])
        
        # Export to ONNX
        onnx_path = export_dir / "pitch_corrector_demo.onnx"
        
        torch.onnx.export(
            model,
            (audio_buffer, target_pitch, correction_strength),
            str(onnx_path),
            input_names=['audio_buffer', 'target_pitch', 'correction_strength'],
            output_names=['corrected_audio', 'confidence'],
            opset_version=11,
            dynamic_axes={
                'audio_buffer': {0: 'batch_size'},
                'corrected_audio': {0: 'batch_size'},
                'confidence': {0: 'batch_size'}
            }
        )
        
        model_size_mb = os.path.getsize(onnx_path) / (1024 * 1024)
        print(f"‚úÖ ONNX model exported: {onnx_path} ({model_size_mb:.2f} MB)")
        
        # Step 4: Create model configuration
        print("\n‚öôÔ∏è Step 4: Creating configuration...")
        
        config = {
            "model_name": "pitch_corrector_demo",
            "model_type": "pitch_correction",
            "version": "1.0.0",
            "input_size": 512,
            "sample_rate": 44100,
            "expected_latency_ms": 1.0,
            "model_parameters": {
                "hidden_size": 128,
                "num_layers": 2,
                "total_parameters": sum(p.numel() for p in model.parameters())
            },
            "training_info": {
                "framework": "PyTorch",
                "export_format": "ONNX",
                "opset_version": 11
            },
            "deployment_notes": [
                "Model trained for real-time pitch correction",
                "Compatible with autotune-real-time-audio-tuner",
                "Fallback to traditional processing if model fails"
            ]
        }
        
        config_path = export_dir / "pitch_corrector_demo_config.json"
        with open(config_path, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"‚úÖ Configuration saved: {config_path}")
        
        # Step 5: Deploy to C++ engine (if available)
        print("\nüöÄ Step 5: Deploying to C++ engine...")
        
        cpp_project_path = Path("../autotune-real-time-audio-tuner")
        
        if cpp_project_path.exists():
            # Create models directory in C++ project
            cpp_models_dir = cpp_project_path / "models"
            cpp_models_dir.mkdir(exist_ok=True)
            
            # Copy model and config
            shutil.copy2(onnx_path, cpp_models_dir / "pitch_corrector.onnx")
            shutil.copy2(config_path, cpp_models_dir / "pitch_corrector_config.json")
            
            print(f"‚úÖ Model deployed to C++ engine: {cpp_models_dir}")
            print("‚úÖ Ready for real-time processing!")
            
            # Create deployment verification
            verification_script = cpp_models_dir / "verify_deployment.py"
            with open(verification_script, 'w') as f:
                f.write("""#!/usr/bin/env python3
# Quick verification that the model was deployed correctly
import os
import json

model_path = "pitch_corrector.onnx"
config_path = "pitch_corrector_config.json"

if os.path.exists(model_path) and os.path.exists(config_path):
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    print("‚úÖ Model deployment verified!")
    print(f"Model: {config['model_name']}")
    print(f"Size: {os.path.getsize(model_path) / 1024:.1f} KB")
    print(f"Expected latency: {config['expected_latency_ms']} ms")
else:
    print("‚ùå Deployment verification failed!")
""")
            
            print(f"‚úÖ Verification script created: {verification_script}")
            
        else:
            print("‚ö†Ô∏è C++ project not found at ../autotune-real-time-audio-tuner")
            print("   Manual deployment required:")
            print(f"   1. Copy {onnx_path} to C++ project models/ directory")
            print(f"   2. Copy {config_path} to C++ project models/ directory")
        
        # Step 6: Performance test
        print("\n‚ö° Step 6: Performance verification...")
        
        import time
        
        # Test inference speed
        num_tests = 100
        start_time = time.time()
        
        with torch.no_grad():
            for _ in range(num_tests):
                output = model(audio_buffer, target_pitch, correction_strength)
        
        end_time = time.time()
        avg_latency_ms = (end_time - start_time) / num_tests * 1000
        
        # Calculate real-time factor
        buffer_duration_ms = (512 / 44100) * 1000  # ~11.6ms
        real_time_factor = buffer_duration_ms / avg_latency_ms
        
        print(f"‚úÖ Performance test completed:")
        print(f"   Average latency: {avg_latency_ms:.2f} ms")
        print(f"   Real-time factor: {real_time_factor:.1f}x")
        print(f"   Target latency: <5ms ({'‚úÖ PASS' if avg_latency_ms < 5 else '‚ùå FAIL'})")
        
        # Final summary
        print("\n" + "=" * 50)
        print("üéâ DEPLOYMENT COMPLETED SUCCESSFULLY!")
        print("=" * 50)
        print(f"üìÅ Model location: {onnx_path}")
        print(f"‚öôÔ∏è Configuration: {config_path}")
        print(f"‚ö° Performance: {avg_latency_ms:.2f}ms ({real_time_factor:.1f}x real-time)")
        
        if cpp_project_path.exists():
            print(f"üöÄ C++ deployment: Ready for real-time processing")
            print("\nNext steps:")
            print("1. Build the C++ engine with ML support")
            print("2. Test with real audio input")
            print("3. Deploy to production environment")
        else:
            print("\nNext steps:")
            print("1. Copy model files to C++ project")
            print("2. Build C++ engine with ONNX Runtime support")
            print("3. Test integration")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Deployment failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Main deployment function"""
    success = train_and_deploy_model()
    
    if success:
        print("\nüéØ INTEGRATION STATUS: ‚úÖ READY FOR PRODUCTION")
        return 0
    else:
        print("\nüéØ INTEGRATION STATUS: ‚ùå NEEDS ATTENTION")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
